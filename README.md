# FrameSession Caching â€“ Prior Art Disclosure and Reference Implementation

This repository documents and demonstrates **FrameSession Caching**, a method for persisting and reusing transformer inference state to enable efficient, deterministic semantic retrieval over large corpora.

It serves as both a **prior art disclosure** and a **reference implementation**, covering:

- Persistent serialization of key/value attention state and RNG metadata (".framesession" files)
- Hierarchical multi-pass query orchestration (HDM reasoning)
- Benchmark results across quantized transformer models
- Integration with a content management pipeline (ThoughtFrame.AI / eMediaDB)
- Experimental logs and corpus samples

---

## ğŸ” Overview

**FrameSession Caching** enables transformer models to:
- Ingest documents once and reuse latent state across future queries
- Resume generation deterministically without re-prefill
- Perform hierarchical drill-down and coarse-to-fine relevance scoring
- Support low-latency semantic access to large, slow-changing corpora

Example domains:
- Legal documents, standards, textbooks
- DAM systems, enterprise knowledge bases
- Education and compliance workflows

---

## ğŸ“„ Included

- `framesession-disclosure.md` â€“ Full technical disclosure (Markdown source)
- `framesession-disclosure.pdf` â€“ Exported PDF version
- `framesession-disclosure.sha256` â€“ SHA-256 hash for verification
- `src/` â€“ Reference code modules (Java)
- `logs/` â€“ Semantic relevance test logs, model response timing
- `corpus/physics_reference_chunk.pdf` â€“ Sample document used in evaluation

---

## ğŸ“œ License and Use

This work is released to the public domain as prior art. You are free to use, modify, and build on this work **with attribution**.

Please reference the original as:
> Ian Miller, â€œFrameSession Caching for Efficient Semantic Retrieval with Quantized Transformers,â€ ThoughtFrame.AI, October 2025

No patents are being pursued. This is a contribution to the open AI community to prevent enclosure of foundational techniques in persistent transformer orchestration.

---

## ğŸ“« Contact

**Ian Miller, B.Eng (Computer), P.Eng, M.Sc (Technology Management)**  
Founder & Principal Architect  
**ThoughtFrame.AI â€“ The Workflow Engine for Adaptive Intelligence**  
ğŸ“§ ian@thoughtframe.ai  
ğŸŒ [https://thoughtframe.ai](https://thoughtframe.ai)

